{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, unix_timestamp, to_utc_timestamp, from_unixtime, to_date, dayofweek\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format, weekofyear\n",
    "from pyspark.sql.types import StructType, StringType, IntegerType, DoubleType, DateType, LongType, StructField, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# the song_data and log_data are in a cpmpressed format in the workspace so we have to uncompress them so that we can read themtheir \n",
    "# this block of code uncopress the zipped file in their directory that is we have loaded them into our notebook yet\n",
    "#import zipfile\n",
    "#with zipfile.ZipFile('data/log-data.zip', 'r') as zip_ref:\n",
    "#    zip_ref.extractall('data/log-data')\n",
    "#import zipfile\n",
    "#with zipfile.ZipFile('data/song-data.zip', 'r') as zip_ref:\n",
    "#    zip_ref.extractall('data/song-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#instatiting a sparksession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Practice_for_a_notebook\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#showing configuration of spark context\n",
    "#spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# first we read the log_data\n",
    "# the are in a json file format\n",
    "\n",
    "def get_files(filepath = \"data/log-data/\"):\n",
    "    \"\"\" Gets the whole files (as paths) in a certain folder\n",
    "    and saves them in a variable called all_files\n",
    "    INPUT : folder path\n",
    "    OUTPUT : a lsit containg the files in a certain folder\n",
    "    \"\"\"\n",
    "    # we need to import os , glob module\n",
    "    import os\n",
    "    import glob\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root,'*.json'))\n",
    "        for f in files :\n",
    "            all_files.append(os.path.abspath(f))\n",
    "    \n",
    "    return all_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_files())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "list_of_log_files = get_files()\n",
    "alls = spark.read.json(list_of_log_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8056"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alls.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8056"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this cell is responsible for counting how many records are existed in all the file in log-data folder\n",
    "def log_data_row_counter():\n",
    "    \"\"\"\n",
    "    THIS FUNCTION RETURNS HOW MANY ROWS ARE EXISTED IN ALL THE LOG-DATA JSON FILES\n",
    "    \"\"\"\n",
    "    csv_file_path = \"data/total_log_data_csv/\"\n",
    "    total_count_log = 0\n",
    "    for i in get_files():\n",
    "        df = spark.read.json(i)\n",
    "        #df_csv = df.write.save(csv_file_path ,format = \"csv\" , header = True)\n",
    "        current_file_rows_count = df.count()\n",
    "        total_count_log += current_file_rows_count\n",
    "    return total_count_log\n",
    "ab = log_data_row_counter()\n",
    "ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'total_log_data_csv' created\n"
     ]
    }
   ],
   "source": [
    "# this cell is responsible for making a directory in which csv file are loaded\n",
    "def directory_maker(directory,parent_dir):\n",
    "    \"\"\"THIS FUNCTION CRETAES A DIRECTORY\n",
    "    INPUTS:\n",
    "    PARENT DIRECTORY\n",
    "    DIRECTORY\n",
    "    \"\"\"\n",
    "    #directory = \"total_log_data_csv\"\n",
    "    import os\n",
    "    # Parent Directory path\n",
    "    #parent_dir = \"data/\"\n",
    "  \n",
    "    # Path\n",
    "    path = os.path.join(parent_dir, directory)\n",
    "  \n",
    "    os.mkdir(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# before reading the file i had to specify my schema (explicit schema definintion)\n",
    "# first we have to import the types that we may need in our schema types\n",
    "from pyspark.sql.types import StructType, StringType, IntegerType, DoubleType, DateType, LongType, StructField, TimestampType\n",
    "# we need also to convert our json file into one csv so that to load it once and use the schema prperty to explicitly define our schema\n",
    "\n",
    "log_types = StructType([\n",
    "    StructField(\"artist\",StringType(),True),\n",
    "    StructField(\"auth\",StringType(),True),\n",
    "    StructField(\"firstName\",StringType(),True),\n",
    "    StructField(\"gender\",StringType(),True),\n",
    "    StructField(\"itemInSession\",LongType(),True),\n",
    "    StructField(\"lastName\",StringType(),True),\n",
    "    StructField(\"length\",DoubleType(),True),\n",
    "    StructField(\"level\",StringType(),True),\n",
    "    StructField(\"location\",StringType(),True),\n",
    "    StructField(\"method\",StringType(),True),\n",
    "    StructField(\"page\",StringType(),True),\n",
    "    StructField(\"registration\",DoubleType(),True),\n",
    "    StructField(\"sessionId\",IntegerType(),True),\n",
    "    StructField(\"song\",StringType(),True),\n",
    "    StructField(\"status\",IntegerType(),True),\n",
    "    StructField(\"ts\",LongType(),True),\n",
    "    StructField(\"userAgent\",StringType(),True),\n",
    "    StructField(\"userId\",IntegerType(),True)\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "log_data = spark.read.json(\"data/log-data/*.json\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8056"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(artist='Harmonia', auth='Logged In', firstName='Ryan', gender='M', itemInSession=0, lastName='Smith', length=655.77751, level='free', location='San Jose-Sunnyvale-Santa Clara, CA', method='PUT', page='NextSong', registration=1541016707796.0, sessionId=583, song='Sehr kosmisch', status=200, ts=1542241826796, userAgent='\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36\"', userId='26'),\n",
       " Row(artist='The Prodigy', auth='Logged In', firstName='Ryan', gender='M', itemInSession=1, lastName='Smith', length=260.07465, level='free', location='San Jose-Sunnyvale-Santa Clara, CA', method='PUT', page='NextSong', registration=1541016707796.0, sessionId=583, song='The Big Gundown', status=200, ts=1542242481796, userAgent='\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36\"', userId='26')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# i have to cast the data types\n",
    "# _c means casted\n",
    "log_data = log_data.withColumn(\"itemInSession_c\", log_data[\"itemInSession\"].cast(IntegerType())).drop(\"itemInSession\")\n",
    "log_data = log_data.withColumn(\"sessionId_c\", log_data[\"sessionId\"].cast(IntegerType())).drop(\"sessionId\")\n",
    "log_data = log_data.withColumn(\"status_c\", log_data[\"status\"].cast(IntegerType())).drop(\"status\")\n",
    "\n",
    "\n",
    "log_data = log_data.withColumn(\"as_date_C\", to_utc_timestamp(from_unixtime(col(\"ts\")/1000,'yyyy-MM-dd HH:mm:ss'),'EST')).drop(\"ts\")\n",
    "\n",
    "\n",
    "#df = log_data.withColumn(\"timestamp\",unix_timestamp(log_data.ts, 'yyyy/MM/dd HH:mm:ss').cast(TimestampType()))\n",
    "log_data = log_data.withColumn(\"userId_C\", log_data[\"userId\"].cast(IntegerType())).drop(\"userId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- itemInSession_c: integer (nullable = true)\n",
      " |-- sessionId_c: integer (nullable = true)\n",
      " |-- status_c: integer (nullable = true)\n",
      " |-- as_date_C: timestamp (nullable = true)\n",
      " |-- userId_C: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(artist='Harmonia', auth='Logged In', firstName='Ryan', gender='M', lastName='Smith', length=655.77751, level='free', location='San Jose-Sunnyvale-Santa Clara, CA', method='PUT', page='NextSong', registration=1541016707796.0, song='Sehr kosmisch', userAgent='\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36\"', itemInSession_c=0, sessionId_c=583, status_c=200, as_date_C=datetime.datetime(2018, 11, 15, 5, 30, 26), userId_C=26),\n",
       " Row(artist='The Prodigy', auth='Logged In', firstName='Ryan', gender='M', lastName='Smith', length=260.07465, level='free', location='San Jose-Sunnyvale-Santa Clara, CA', method='PUT', page='NextSong', registration=1541016707796.0, song='The Big Gundown', userAgent='\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36\"', itemInSession_c=1, sessionId_c=583, status_c=200, as_date_C=datetime.datetime(2018, 11, 15, 5, 41, 21), userId_C=26)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this cell shows that if we did not use distinct in the select statement that\n",
    "#loads data in the user table we would get one users many times and that is not needed\n",
    "log_data.where(log_data.userId_C=='26').take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting for user table\n",
    "user_table_column_list = [\"userId_C\",\"firstName\",\"lastName\",\"gender\",\"level\"]\n",
    "user_table_df = log_data.select(*user_table_column_list).distinct()\n",
    "user_table_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6820"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selecting for songplays tables so that the page is NextSong\n",
    "song_play_column_list = [\"\",\"as_date_C\",\"userId_C\",\"level\",\"\",\"\",\"sessionId_c\",\"location\",\"userAgent\"]\n",
    "song_play_df = log_data.select(*song_play_column_list).where(log_data.page=='NextSong')\n",
    "song_play_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+---+----+-----+----+--------+\n",
      "|star_time|hour|day|week|month|year|week_day|\n",
      "+---------+----+---+----+-----+----+--------+\n",
      "| 05:30:26|   5| 15|  46|   11|2018|       5|\n",
      "| 05:41:21|   5| 15|  46|   11|2018|       5|\n",
      "| 05:45:41|   5| 15|  46|   11|2018|       5|\n",
      "| 06:57:51|   6| 15|  46|   11|2018|       5|\n",
      "| 08:29:37|   8| 15|  46|   11|2018|       5|\n",
      "| 08:44:09|   8| 15|  46|   11|2018|       5|\n",
      "| 08:44:20|   8| 15|  46|   11|2018|       5|\n",
      "| 10:34:34|  10| 15|  46|   11|2018|       5|\n",
      "| 10:37:57|  10| 15|  46|   11|2018|       5|\n",
      "| 10:48:55|  10| 15|  46|   11|2018|       5|\n",
      "+---------+----+---+----+-----+----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting for time table\n",
    "log_data.\\\n",
    "withColumn(\"star_time\", date_format(log_data.as_date_C,\"HH:mm:ss\")).\\\n",
    "withColumn('hour',date_format(log_data.as_date_C ,\"h\")).\\\n",
    "withColumn('day',date_format(log_data.as_date_C ,\"d\")).\\\n",
    "withColumn('week',weekofyear(log_data.as_date_C)).\\\n",
    "withColumn('month',month(log_data.as_date_C)).\\\n",
    "withColumn('year',year(log_data.as_date_C)).\\\n",
    "withColumn('week_day',dayofweek(log_data.as_date_C)).\\\n",
    "select(\"star_time\",\"hour\",\"day\",\"week\",\"month\",\"year\",\"week_day\").show(10)\n",
    "\n",
    "#withColumn('minute',date_format(log_data.as_date_C ,\"m\")).\\\n",
    "#withColumn('seconds',date_format(log_data.as_date_C ,\"s\")).\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# here i will start reading song data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# before reading the file i had to specify my schema (explicit schema definintion)\n",
    "\n",
    "song_types = StructType([\n",
    "    StructField(\"artist_id\",StringType()),\n",
    "    StructField(\"artist_latitude\",StringType()),\n",
    "    StructField(\"artist_location\",StringType()),\n",
    "    StructField(\"artist_longitude\",StringType()),\n",
    "    StructField(\"artist_name\",StringType()),\n",
    "    StructField(\"duration\",DoubleType()),\n",
    "    StructField(\"num_songs\",IntegerType()),\n",
    "    StructField(\"song_id\",StringType()),\n",
    "    StructField(\"title\",StringType()),\n",
    "    StructField(\"year\",IntegerType())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "song_data = spark.read.json(\"data/song-data/song_data/*/*/*/*.json\", schema = song_types)\n",
    "\n",
    "#data/song-data/song_data/A/A/A/TRAAAAW128F429D538.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(artist_id='ARDR4AC1187FB371A1', artist_latitude=None, artist_location='', artist_longitude=None, artist_name='Montserrat Caballé;Placido Domingo;Vicente Sardinero;Judith Blegen;Sherrill Milnes;Georg Solti', duration=511.16363, num_songs=1, song_id='SOBAYLL12A8C138AF9', title='Sono andati? Fingevo di dormire', year=0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: string (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: integer (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "song_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# choosing artist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_table_column_list = [\"artist_id\",\"artist_name\",\"artist_location\",\"artist_longitude\",\"artist_latitude\"]\n",
    "artist_table_df = song_data.select(*artist_table_column_list).distinct()\n",
    "artist_table_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# choosing song data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_table_column_list = [\"song_id\",\"title\",\"artist_id\",\"year\",\"duration\"]\n",
    "song_table_df = song_data.select(*song_table_column_list).distinct()\n",
    "song_table_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5c6b4d5d9db0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
